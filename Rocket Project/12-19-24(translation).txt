12-19-24:
D:\RocketProject\RocketProject\Rocket Project\venv\lib\site-packages\torch\__init__.py:749: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at ..\torch\csrc\tensor\python_tensor.cpp:433.)
  _C._set_default_tensor_type(t)

            ┐  ╖
        ╓╖╬│╡  ││╬╖╖
    ╓╖╬│││││┘  ╬│││││╬╖
 ╖╬│││││╬╜        ╙╬│││││╖╖                               ╗╗╗
 ╬╬╬╬╖││╦╖        ╖╬││╗╣╣╣╬      ╟╣╣╬    ╟╣╣╣             ╜╜╜  ╟╣╣
 ╬╬╬╬╬╬╬╬╖│╬╖╖╓╬╪│╓╣╣╣╣╣╣╣╬      ╟╣╣╬    ╟╣╣╣ ╒╣╣╖╗╣╣╣╗   ╣╣╣ ╣╣╣╣╣╣ ╟╣╣╖   ╣╣╣
 ╬╬╬╬┐  ╙╬╬╬╬│╓╣╣╣╝╜  ╫╣╣╣╬      ╟╣╣╬    ╟╣╣╣ ╟╣╣╣╙ ╙╣╣╣  ╣╣╣ ╙╟╣╣╜╙  ╫╣╣  ╟╣╣ 
 ╬╬╬╬┐     ╙╬╬╣╣      ╫╣╣╣╬      ╟╣╣╬    ╟╣╣╣ ╟╣╣╬   ╣╣╣  ╣╣╣  ╟╣╣     ╣╣╣┌╣╣╜ 
 ╬╬╬╜       ╬╬╣╣      ╙╝╣╣╬      ╙╣╣╣╗╖╓╗╣╣╣╜ ╟╣╣╬   ╣╣╣  ╣╣╣  ╟╣╣╦╓    ╣╣╣╣╣  
 ╙   ╓╦╖    ╬╬╣╣   ╓╗╗╖            ╙╝╣╣╣╣╝╜   ╘╝╝╜   ╝╝╝  ╝╝╝   ╙╣╣╣    ╟╣╣╣   
   ╩╬╬╬╬╬╬╦╦╬╬╣╣╗╣╣╣╣╣╣╣╝                                             ╫╣╣╣╣
      ╙╬╬╬╬╬╬╬╣╣╣╣╣╣╝╜
          ╙╬╬╬╣╣╣╜
             ╙

 Version information:
  ml-agents: 1.0.0,
  ml-agents-envs: 1.0.0,
  Communicator API: 1.5.0,
  PyTorch: 2.3.1+cu121
D:\RocketProject\RocketProject\Rocket Project\venv\lib\site-packages\torch\__init__.py:749: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at ..\torch\csrc\tensor\python_tensor.cpp:433.)
  _C._set_default_tensor_type(t)
[INFO] Listening on port 5004. Start training by pressing the Play button in the Unity Editor.
[INFO] Connected to Unity environment with package version 2.0.1 and communication version 1.5.0
[INFO] Connected new brain: RocketLanding?team=0
[INFO] Hyperparameters for behavior name RocketLanding: 
        trainer_type:   ppo
        hyperparameters:
          batch_size:   1024
          buffer_size:  20480
          learning_rate:        0.0003
          beta: 0.001
          epsilon:      0.2
          lambd:        0.95
          num_epoch:    3
          shared_critic:        False
          learning_rate_schedule:       linear
          beta_schedule:        linear
          epsilon_schedule:     linear
        checkpoint_interval:    500000
        network_settings:
          normalize:    True
          hidden_units: 1024
          num_layers:   5
          vis_encode_type:      simple
          memory:       None
          goal_conditioning_type:       hyper
          deterministic:        False
        reward_signals:
          extrinsic:
            gamma:      0.99
            strength:   1.0
            network_settings:
              normalize:        False
              hidden_units:     128
              num_layers:       2
              vis_encode_type:  simple
              memory:   None
              goal_conditioning_type:   hyper
              deterministic:    False
        init_path:      results\newlanding14alt\RocketLanding\checkpoint.pt
        keep_checkpoints:       5
        even_checkpoints:       False
        max_steps:      750000
        time_horizon:   128
        summary_freq:   20000
        threaded:       False
        self_play:      None
        behavioral_cloning:     None
[INFO] Initializing from results\newlanding14alt\RocketLanding\checkpoint.pt.
[WARNING] Failed to load for module Policy. Initializing
[WARNING] Failed to load for module Optimizer:value_optimizer. Initializing
[INFO] Starting training from step 0 and saving to results\translation1\RocketLanding.
[INFO] RocketLanding. Step: 20000. Time Elapsed: 20.059 s. Mean Reward: -1.171. Std of Reward: 1.899. Training.
[INFO] RocketLanding. Step: 40000. Time Elapsed: 32.431 s. Mean Reward: -1.801. Std of Reward: 3.253. Training.
[INFO] RocketLanding. Step: 60000. Time Elapsed: 44.541 s. Mean Reward: -2.188. Std of Reward: 2.959. Training.
[INFO] RocketLanding. Step: 80000. Time Elapsed: 56.324 s. Mean Reward: -1.997. Std of Reward: 3.034. Training.
[INFO] RocketLanding. Step: 100000. Time Elapsed: 68.531 s. Mean Reward: -2.085. Std of Reward: 2.862. Training.
[INFO] RocketLanding. Step: 120000. Time Elapsed: 80.560 s. Mean Reward: -1.473. Std of Reward: 3.034. Training.
[INFO] RocketLanding. Step: 140000. Time Elapsed: 92.557 s. Mean Reward: -1.114. Std of Reward: 3.422. Training.
[INFO] RocketLanding. Step: 160000. Time Elapsed: 105.743 s. Mean Reward: -0.830. Std of Reward: 1.973. Training.
[INFO] RocketLanding. Step: 180000. Time Elapsed: 117.979 s. Mean Reward: -1.000. Std of Reward: 2.868. Training.
[INFO] RocketLanding. Step: 200000. Time Elapsed: 130.728 s. Mean Reward: 0.229. Std of Reward: 6.902. Training.
[INFO] RocketLanding. Step: 220000. Time Elapsed: 142.977 s. Mean Reward: 3.123. Std of Reward: 9.282. Training.
[INFO] RocketLanding. Step: 240000. Time Elapsed: 155.169 s. Mean Reward: 2.840. Std of Reward: 9.375. Training.
[INFO] RocketLanding. Step: 260000. Time Elapsed: 166.894 s. Mean Reward: 2.698. Std of Reward: 8.164. Training.
[INFO] RocketLanding. Step: 280000. Time Elapsed: 179.003 s. Mean Reward: 3.163. Std of Reward: 11.068. Training.
[INFO] RocketLanding. Step: 300000. Time Elapsed: 191.244 s. Mean Reward: 4.891. Std of Reward: 12.479. Training.
[INFO] RocketLanding. Step: 320000. Time Elapsed: 203.306 s. Mean Reward: 5.351. Std of Reward: 11.947. Training.
[INFO] RocketLanding. Step: 340000. Time Elapsed: 215.591 s. Mean Reward: 4.629. Std of Reward: 9.695. Training.
[INFO] RocketLanding. Step: 360000. Time Elapsed: 228.057 s. Mean Reward: 7.368. Std of Reward: 13.881. Training.
[INFO] RocketLanding. Step: 380000. Time Elapsed: 240.259 s. Mean Reward: 4.555. Std of Reward: 12.596. Training.
[INFO] RocketLanding. Step: 400000. Time Elapsed: 252.564 s. Mean Reward: 6.419. Std of Reward: 13.042. Training.
[INFO] RocketLanding. Step: 420000. Time Elapsed: 264.611 s. Mean Reward: 9.033. Std of Reward: 16.564. Training.
[INFO] RocketLanding. Step: 440000. Time Elapsed: 276.600 s. Mean Reward: 6.059. Std of Reward: 11.719. Training.
[INFO] RocketLanding. Step: 460000. Time Elapsed: 288.931 s. Mean Reward: 6.354. Std of Reward: 13.269. Training.
[INFO] RocketLanding. Step: 480000. Time Elapsed: 300.941 s. Mean Reward: 7.089. Std of Reward: 14.762. Training.
[INFO] RocketLanding. Step: 500000. Time Elapsed: 312.848 s. Mean Reward: 7.758. Std of Reward: 14.699. Training.
[INFO] Exported results\translation1\RocketLanding\RocketLanding-499908.onnx
[INFO] RocketLanding. Step: 520000. Time Elapsed: 325.515 s. Mean Reward: 5.118. Std of Reward: 10.793. Training.
[INFO] RocketLanding. Step: 540000. Time Elapsed: 337.507 s. Mean Reward: 8.540. Std of Reward: 14.559. Training.
[INFO] RocketLanding. Step: 560000. Time Elapsed: 349.606 s. Mean Reward: 8.129. Std of Reward: 15.262. Training.
[INFO] RocketLanding. Step: 580000. Time Elapsed: 361.241 s. Mean Reward: 9.056. Std of Reward: 15.477. Training.
[INFO] RocketLanding. Step: 600000. Time Elapsed: 373.232 s. Mean Reward: 7.845. Std of Reward: 13.487. Training.
[INFO] RocketLanding. Step: 620000. Time Elapsed: 385.474 s. Mean Reward: 10.993. Std of Reward: 16.857. Training.
[INFO] RocketLanding. Step: 640000. Time Elapsed: 397.096 s. Mean Reward: 9.707. Std of Reward: 15.079. Training.
[INFO] RocketLanding. Step: 660000. Time Elapsed: 409.831 s. Mean Reward: 12.283. Std of Reward: 16.277. Training.
[INFO] RocketLanding. Step: 680000. Time Elapsed: 421.833 s. Mean Reward: 12.038. Std of Reward: 16.864. Training.
[INFO] RocketLanding. Step: 700000. Time Elapsed: 431.264 s. Mean Reward: 6.837. Std of Reward: 12.086. Training.
[INFO] RocketLanding. Step: 720000. Time Elapsed: 443.222 s. Mean Reward: 8.669. Std of Reward: 15.140. Training.
[INFO] RocketLanding. Step: 740000. Time Elapsed: 455.213 s. Mean Reward: 9.226. Std of Reward: 14.194. Training.
[INFO] Exported results\translation1\RocketLanding\RocketLanding-750085.onnx
[INFO] Copied results\translation1\RocketLanding\RocketLanding-750085.onnx to results\translation1\RocketLanding.onnx.
D:\RocketProject\RocketProject\Rocket Project\venv\lib\site-packages\torch\__init__.py:749: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at ..\torch\csrc\tensor\python_tensor.cpp:433.)
  _C._set_default_tensor_type(t)

            ┐  ╖
        ╓╖╬│╡  ││╬╖╖
    ╓╖╬│││││┘  ╬│││││╬╖
 ╖╬│││││╬╜        ╙╬│││││╖╖                               ╗╗╗
 ╬╬╬╬╖││╦╖        ╖╬││╗╣╣╣╬      ╟╣╣╬    ╟╣╣╣             ╜╜╜  ╟╣╣
 ╬╬╬╬╬╬╬╬╖│╬╖╖╓╬╪│╓╣╣╣╣╣╣╣╬      ╟╣╣╬    ╟╣╣╣ ╒╣╣╖╗╣╣╣╗   ╣╣╣ ╣╣╣╣╣╣ ╟╣╣╖   ╣╣╣
 ╬╬╬╬┐  ╙╬╬╬╬│╓╣╣╣╝╜  ╫╣╣╣╬      ╟╣╣╬    ╟╣╣╣ ╟╣╣╣╙ ╙╣╣╣  ╣╣╣ ╙╟╣╣╜╙  ╫╣╣  ╟╣╣
 ╬╬╬╬┐     ╙╬╬╣╣      ╫╣╣╣╬      ╟╣╣╬    ╟╣╣╣ ╟╣╣╬   ╣╣╣  ╣╣╣  ╟╣╣     ╣╣╣┌╣╣╜
 ╬╬╬╜       ╬╬╣╣      ╙╝╣╣╬      ╙╣╣╣╗╖╓╗╣╣╣╜ ╟╣╣╬   ╣╣╣  ╣╣╣  ╟╣╣╦╓    ╣╣╣╣╣
 ╙   ╓╦╖    ╬╬╣╣   ╓╗╗╖            ╙╝╣╣╣╣╝╜   ╘╝╝╜   ╝╝╝  ╝╝╝   ╙╣╣╣    ╟╣╣╣
   ╩╬╬╬╬╬╬╦╦╬╬╣╣╗╣╣╣╣╣╣╣╝                                             ╫╣╣╣╣
      ╙╬╬╬╬╬╬╬╣╣╣╣╣╣╝╜
          ╙╬╬╬╣╣╣╜
             ╙

 Version information:
  ml-agents: 1.0.0,
  ml-agents-envs: 1.0.0,
  Communicator API: 1.5.0,
  PyTorch: 2.3.1+cu121
D:\RocketProject\RocketProject\Rocket Project\venv\lib\site-packages\torch\__init__.py:749: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at ..\torch\csrc\tensor\python_tensor.cpp:433.)
  _C._set_default_tensor_type(t)
[INFO] Listening on port 5004. Start training by pressing the Play button in the Unity Editor.
[INFO] Connected to Unity environment with package version 2.0.1 and communication version 1.5.0
[INFO] Connected new brain: RocketLanding?team=0
[INFO] Hyperparameters for behavior name RocketLanding: 
        trainer_type:   ppo
        hyperparameters:
          batch_size:   1024
          buffer_size:  20480
          learning_rate:        0.0003
          beta: 0.001
          epsilon:      0.2
          lambd:        0.95
          num_epoch:    3
          shared_critic:        False
          learning_rate_schedule:       linear
          beta_schedule:        linear
          epsilon_schedule:     linear
        checkpoint_interval:    500000
        network_settings:
          normalize:    True
          hidden_units: 1024
          num_layers:   5
          vis_encode_type:      simple
          memory:       None
          goal_conditioning_type:       hyper
          deterministic:        False
        reward_signals:
          extrinsic:
            gamma:      0.99
            strength:   1.0
            network_settings:
              normalize:        False
              hidden_units:     128
              num_layers:       2
              vis_encode_type:  simple
              memory:   None
              goal_conditioning_type:   hyper
              deterministic:    False
        init_path:      results\translation1\RocketLanding\checkpoint.pt
        keep_checkpoints:       5
        even_checkpoints:       False
        max_steps:      750000
        time_horizon:   128
        summary_freq:   20000
        threaded:       False
        self_play:      None
        behavioral_cloning:     None
[INFO] Initializing from results\translation1\RocketLanding\checkpoint.pt.
[INFO] Starting training from step 0 and saving to results\translation2\RocketLanding.
[INFO] RocketLanding. Step: 20000. Time Elapsed: 19.812 s. Mean Reward: -0.869. Std of Reward: 0.756. Training.
[INFO] RocketLanding. Step: 40000. Time Elapsed: 31.579 s. Mean Reward: 7.970. Std of Reward: 10.133. Training.
[INFO] RocketLanding. Step: 60000. Time Elapsed: 44.460 s. Mean Reward: 12.976. Std of Reward: 19.044. Training.
[INFO] RocketLanding. Step: 80000. Time Elapsed: 56.255 s. Mean Reward: 6.431. Std of Reward: 9.097. Training.
[INFO] RocketLanding. Step: 100000. Time Elapsed: 68.685 s. Mean Reward: 23.596. Std of Reward: 22.187. Training.
[INFO] RocketLanding. Step: 120000. Time Elapsed: 80.593 s. Mean Reward: 15.440. Std of Reward: 20.987. Training.
[INFO] RocketLanding. Step: 140000. Time Elapsed: 92.701 s. Mean Reward: 15.180. Std of Reward: 19.831. Training.
[INFO] RocketLanding. Step: 160000. Time Elapsed: 105.024 s. Mean Reward: 21.167. Std of Reward: 24.067. Training.
[INFO] RocketLanding. Step: 180000. Time Elapsed: 116.938 s. Mean Reward: 20.326. Std of Reward: 24.537. Training.
[INFO] RocketLanding. Step: 200000. Time Elapsed: 129.844 s. Mean Reward: 18.763. Std of Reward: 24.393. Training.
[INFO] RocketLanding. Step: 220000. Time Elapsed: 142.656 s. Mean Reward: 13.577. Std of Reward: 21.373. Training.
[INFO] RocketLanding. Step: 240000. Time Elapsed: 154.542 s. Mean Reward: 17.589. Std of Reward: 22.415. Training.
[INFO] RocketLanding. Step: 260000. Time Elapsed: 167.458 s. Mean Reward: 21.069. Std of Reward: 24.791. Training.
[INFO] RocketLanding. Step: 280000. Time Elapsed: 179.334 s. Mean Reward: 17.751. Std of Reward: 23.156. Training.
[INFO] RocketLanding. Step: 300000. Time Elapsed: 192.129 s. Mean Reward: 20.300. Std of Reward: 23.489. Training.
[INFO] RocketLanding. Step: 320000. Time Elapsed: 204.407 s. Mean Reward: 18.972. Std of Reward: 21.599. Training.
[INFO] RocketLanding. Step: 340000. Time Elapsed: 216.652 s. Mean Reward: 15.292. Std of Reward: 21.062. Training.
[INFO] RocketLanding. Step: 360000. Time Elapsed: 229.659 s. Mean Reward: 17.330. Std of Reward: 22.744. Training.
[INFO] RocketLanding. Step: 380000. Time Elapsed: 241.857 s. Mean Reward: 16.544. Std of Reward: 21.796. Training.
[INFO] RocketLanding. Step: 400000. Time Elapsed: 254.231 s. Mean Reward: 18.334. Std of Reward: 24.203. Training.
[INFO] RocketLanding. Step: 420000. Time Elapsed: 266.429 s. Mean Reward: 19.196. Std of Reward: 25.280. Training.
[INFO] RocketLanding. Step: 440000. Time Elapsed: 278.372 s. Mean Reward: 13.574. Std of Reward: 23.356. Training.
[INFO] RocketLanding. Step: 460000. Time Elapsed: 290.761 s. Mean Reward: 20.490. Std of Reward: 23.375. Training.
[INFO] RocketLanding. Step: 480000. Time Elapsed: 302.111 s. Mean Reward: 26.498. Std of Reward: 28.740. Training.
[INFO] RocketLanding. Step: 500000. Time Elapsed: 314.395 s. Mean Reward: 21.890. Std of Reward: 25.940. Training.
[INFO] Exported results\translation2\RocketLanding\RocketLanding-499895.onnx
[INFO] RocketLanding. Step: 520000. Time Elapsed: 326.699 s. Mean Reward: 22.051. Std of Reward: 24.558. Training.
[INFO] RocketLanding. Step: 540000. Time Elapsed: 338.758 s. Mean Reward: 22.698. Std of Reward: 27.977. Training.
[INFO] RocketLanding. Step: 560000. Time Elapsed: 350.606 s. Mean Reward: 27.269. Std of Reward: 27.616. Training.
[INFO] RocketLanding. Step: 580000. Time Elapsed: 361.955 s. Mean Reward: 19.232. Std of Reward: 25.261. Training.
[INFO] RocketLanding. Step: 600000. Time Elapsed: 374.544 s. Mean Reward: 22.417. Std of Reward: 24.431. Training.
[INFO] RocketLanding. Step: 620000. Time Elapsed: 386.226 s. Mean Reward: 31.645. Std of Reward: 25.327. Training.
[INFO] RocketLanding. Step: 640000. Time Elapsed: 398.182 s. Mean Reward: 27.447. Std of Reward: 27.166. Training.
[INFO] RocketLanding. Step: 660000. Time Elapsed: 410.613 s. Mean Reward: 27.849. Std of Reward: 29.060. Training.
[INFO] RocketLanding. Step: 680000. Time Elapsed: 422.225 s. Mean Reward: 35.215. Std of Reward: 32.075. Training.
[INFO] RocketLanding. Step: 700000. Time Elapsed: 434.671 s. Mean Reward: 25.475. Std of Reward: 26.793. Training.
[INFO] RocketLanding. Step: 720000. Time Elapsed: 443.489 s. Mean Reward: 18.683. Std of Reward: 24.610. Training.
[INFO] RocketLanding. Step: 740000. Time Elapsed: 455.092 s. Mean Reward: 35.057. Std of Reward: 34.746. Training.
[INFO] Exported results\translation2\RocketLanding\RocketLanding-750097.onnx
[INFO] Copied results\translation2\RocketLanding\RocketLanding-750097.onnx to results\translation2\RocketLanding.onnx.
D:\RocketProject\RocketProject\Rocket Project\venv\lib\site-packages\torch\__init__.py:749: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at ..\torch\csrc\tensor\python_tensor.cpp:433.)
  _C._set_default_tensor_type(t)

            ┐  ╖
        ╓╖╬│╡  ││╬╖╖
    ╓╖╬│││││┘  ╬│││││╬╖
 ╖╬│││││╬╜        ╙╬│││││╖╖                               ╗╗╗
 ╬╬╬╬╖││╦╖        ╖╬││╗╣╣╣╬      ╟╣╣╬    ╟╣╣╣             ╜╜╜  ╟╣╣
 ╬╬╬╬╬╬╬╬╖│╬╖╖╓╬╪│╓╣╣╣╣╣╣╣╬      ╟╣╣╬    ╟╣╣╣ ╒╣╣╖╗╣╣╣╗   ╣╣╣ ╣╣╣╣╣╣ ╟╣╣╖   ╣╣╣
 ╬╬╬╬┐  ╙╬╬╬╬│╓╣╣╣╝╜  ╫╣╣╣╬      ╟╣╣╬    ╟╣╣╣ ╟╣╣╣╙ ╙╣╣╣  ╣╣╣ ╙╟╣╣╜╙  ╫╣╣  ╟╣╣
 ╬╬╬╬┐     ╙╬╬╣╣      ╫╣╣╣╬      ╟╣╣╬    ╟╣╣╣ ╟╣╣╬   ╣╣╣  ╣╣╣  ╟╣╣     ╣╣╣┌╣╣╜
 ╬╬╬╜       ╬╬╣╣      ╙╝╣╣╬      ╙╣╣╣╗╖╓╗╣╣╣╜ ╟╣╣╬   ╣╣╣  ╣╣╣  ╟╣╣╦╓    ╣╣╣╣╣
 ╙   ╓╦╖    ╬╬╣╣   ╓╗╗╖            ╙╝╣╣╣╣╝╜   ╘╝╝╜   ╝╝╝  ╝╝╝   ╙╣╣╣    ╟╣╣╣
   ╩╬╬╬╬╬╬╦╦╬╬╣╣╗╣╣╣╣╣╣╣╝                                             ╫╣╣╣╣
      ╙╬╬╬╬╬╬╬╣╣╣╣╣╣╝╜
          ╙╬╬╬╣╣╣╜
             ╙

 Version information:
  ml-agents: 1.0.0,
  ml-agents-envs: 1.0.0,
  Communicator API: 1.5.0,
  PyTorch: 2.3.1+cu121
D:\RocketProject\RocketProject\Rocket Project\venv\lib\site-packages\torch\__init__.py:749: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at ..\torch\csrc\tensor\python_tensor.cpp:433.)
  _C._set_default_tensor_type(t)
[INFO] Listening on port 5004. Start training by pressing the Play button in the Unity Editor.
[INFO] Connected to Unity environment with package version 2.0.1 and communication version 1.5.0
[INFO] Connected new brain: RocketLanding?team=0
[INFO] Hyperparameters for behavior name RocketLanding: 
        trainer_type:   ppo
        hyperparameters:
          batch_size:   1024
          buffer_size:  20480
          learning_rate:        0.0003
          beta: 0.001
          epsilon:      0.2
          lambd:        0.95
          num_epoch:    3
          shared_critic:        False
          learning_rate_schedule:       linear
          beta_schedule:        linear
          epsilon_schedule:     linear
        checkpoint_interval:    500000
        network_settings:
          normalize:    True
          hidden_units: 1024
          num_layers:   5
          vis_encode_type:      simple
          memory:       None
          goal_conditioning_type:       hyper
          deterministic:        False
        reward_signals:
          extrinsic:
            gamma:      0.99
            strength:   1.0
            network_settings:
              normalize:        False
              hidden_units:     128
              num_layers:       2
              vis_encode_type:  simple
              memory:   None
              goal_conditioning_type:   hyper
              deterministic:    False
        init_path:      results\translation2\RocketLanding\checkpoint.pt
        keep_checkpoints:       5
        even_checkpoints:       False
        max_steps:      750000
        time_horizon:   128
        summary_freq:   20000
        threaded:       False
        self_play:      None
        behavioral_cloning:     None
[INFO] Initializing from results\translation2\RocketLanding\checkpoint.pt.
[INFO] Starting training from step 0 and saving to results\translation3\RocketLanding.
[INFO] RocketLanding. Step: 20000. Time Elapsed: 20.868 s. Mean Reward: -0.256. Std of Reward: 3.137. Training.
[INFO] RocketLanding. Step: 40000. Time Elapsed: 32.415 s. Mean Reward: 18.848. Std of Reward: 12.387. Training.
[INFO] RocketLanding. Step: 60000. Time Elapsed: 44.848 s. Mean Reward: 16.443. Std of Reward: 20.016. Training.
[INFO] RocketLanding. Step: 80000. Time Elapsed: 56.886 s. Mean Reward: 9.242. Std of Reward: 17.233. Training.
[INFO] RocketLanding. Step: 100000. Time Elapsed: 69.214 s. Mean Reward: 8.700. Std of Reward: 15.708. Training.
[INFO] RocketLanding. Step: 120000. Time Elapsed: 80.724 s. Mean Reward: 17.330. Std of Reward: 18.417. Training.
[INFO] RocketLanding. Step: 140000. Time Elapsed: 92.945 s. Mean Reward: 16.306. Std of Reward: 20.008. Training.
[INFO] RocketLanding. Step: 160000. Time Elapsed: 104.955 s. Mean Reward: 21.826. Std of Reward: 23.922. Training.
[INFO] RocketLanding. Step: 180000. Time Elapsed: 116.888 s. Mean Reward: 22.629. Std of Reward: 25.264. Training.
[INFO] RocketLanding. Step: 200000. Time Elapsed: 129.284 s. Mean Reward: 29.318. Std of Reward: 29.261. Training.
[INFO] RocketLanding. Step: 220000. Time Elapsed: 141.727 s. Mean Reward: 21.437. Std of Reward: 24.627. Training.
[INFO] RocketLanding. Step: 240000. Time Elapsed: 154.518 s. Mean Reward: 21.906. Std of Reward: 26.950. Training.
[INFO] RocketLanding. Step: 260000. Time Elapsed: 166.954 s. Mean Reward: 25.732. Std of Reward: 28.556. Training.
[INFO] RocketLanding. Step: 280000. Time Elapsed: 179.184 s. Mean Reward: 31.382. Std of Reward: 33.619. Training.
[INFO] RocketLanding. Step: 300000. Time Elapsed: 191.412 s. Mean Reward: 33.981. Std of Reward: 31.436. Training.
[INFO] RocketLanding. Step: 320000. Time Elapsed: 203.516 s. Mean Reward: 43.418. Std of Reward: 30.604. Training.
[INFO] RocketLanding. Step: 340000. Time Elapsed: 215.704 s. Mean Reward: 26.521. Std of Reward: 26.611. Training.
[INFO] RocketLanding. Step: 360000. Time Elapsed: 227.384 s. Mean Reward: 31.117. Std of Reward: 29.165. Training.
[INFO] RocketLanding. Step: 380000. Time Elapsed: 239.422 s. Mean Reward: 41.202. Std of Reward: 33.216. Training.
[INFO] RocketLanding. Step: 400000. Time Elapsed: 251.656 s. Mean Reward: 34.624. Std of Reward: 32.386. Training.
[INFO] RocketLanding. Step: 420000. Time Elapsed: 263.151 s. Mean Reward: 33.417. Std of Reward: 30.384. Training.
[INFO] RocketLanding. Step: 440000. Time Elapsed: 276.060 s. Mean Reward: 21.223. Std of Reward: 28.645. Training.
[INFO] RocketLanding. Step: 460000. Time Elapsed: 288.396 s. Mean Reward: 25.180. Std of Reward: 27.525. Training.
[INFO] RocketLanding. Step: 480000. Time Elapsed: 300.051 s. Mean Reward: 23.788. Std of Reward: 27.751. Training.
[INFO] RocketLanding. Step: 500000. Time Elapsed: 312.356 s. Mean Reward: 23.328. Std of Reward: 28.716. Training.
[INFO] Exported results\translation3\RocketLanding\RocketLanding-499874.onnx
[INFO] RocketLanding. Step: 520000. Time Elapsed: 324.308 s. Mean Reward: 24.638. Std of Reward: 28.723. Training.
[INFO] RocketLanding. Step: 540000. Time Elapsed: 336.457 s. Mean Reward: 39.816. Std of Reward: 30.045. Training.
[INFO] RocketLanding. Step: 560000. Time Elapsed: 347.880 s. Mean Reward: 28.982. Std of Reward: 31.238. Training.
[INFO] RocketLanding. Step: 580000. Time Elapsed: 360.009 s. Mean Reward: 25.570. Std of Reward: 28.932. Training.
[INFO] RocketLanding. Step: 600000. Time Elapsed: 371.789 s. Mean Reward: 20.562. Std of Reward: 26.735. Training.
[INFO] RocketLanding. Step: 620000. Time Elapsed: 383.774 s. Mean Reward: 33.787. Std of Reward: 34.453. Training.
[INFO] RocketLanding. Step: 640000. Time Elapsed: 395.971 s. Mean Reward: 36.645. Std of Reward: 33.252. Training.
[INFO] RocketLanding. Step: 660000. Time Elapsed: 404.811 s. Mean Reward: 29.486. Std of Reward: 31.564. Training.
[INFO] RocketLanding. Step: 680000. Time Elapsed: 416.986 s. Mean Reward: 29.202. Std of Reward: 29.375. Training.
[INFO] RocketLanding. Step: 700000. Time Elapsed: 428.704 s. Mean Reward: 26.161. Std of Reward: 27.558. Training.
[INFO] RocketLanding. Step: 720000. Time Elapsed: 440.698 s. Mean Reward: 32.113. Std of Reward: 33.179. Training.
[INFO] RocketLanding. Step: 740000. Time Elapsed: 453.571 s. Mean Reward: 26.235. Std of Reward: 31.098. Training.
[INFO] Exported results\translation3\RocketLanding\RocketLanding-750102.onnx
[INFO] Copied results\translation3\RocketLanding\RocketLanding-750102.onnx to results\translation3\RocketLanding.onnx.

1-9-25:

(venv) PS D:\RocketProject\RocketProject\Rocket Project> mlagents-learn config/config.yaml --run-id=translation4 --initialize-from=translation3 --torch-device="cuda" --force
D:\RocketProject\RocketProject\Rocket Project\venv\lib\site-packages\torch\__init__.py:749: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at ..\torch\csrc\tensor\python_tensor.cpp:433.)
  _C._set_default_tensor_type(t)

            ┐  ╖
        ╓╖╬│╡  ││╬╖╖
    ╓╖╬│││││┘  ╬│││││╬╖
 ╖╬│││││╬╜        ╙╬│││││╖╖                               ╗╗╗
 ╬╬╬╬╖││╦╖        ╖╬││╗╣╣╣╬      ╟╣╣╬    ╟╣╣╣             ╜╜╜  ╟╣╣
 ╬╬╬╬╬╬╬╬╖│╬╖╖╓╬╪│╓╣╣╣╣╣╣╣╬      ╟╣╣╬    ╟╣╣╣ ╒╣╣╖╗╣╣╣╗   ╣╣╣ ╣╣╣╣╣╣ ╟╣╣╖   ╣╣╣
 ╬╬╬╬┐  ╙╬╬╬╬│╓╣╣╣╝╜  ╫╣╣╣╬      ╟╣╣╬    ╟╣╣╣ ╟╣╣╣╙ ╙╣╣╣  ╣╣╣ ╙╟╣╣╜╙  ╫╣╣  ╟╣╣ 
 ╬╬╬╬┐     ╙╬╬╣╣      ╫╣╣╣╬      ╟╣╣╬    ╟╣╣╣ ╟╣╣╬   ╣╣╣  ╣╣╣  ╟╣╣     ╣╣╣┌╣╣╜ 
 ╬╬╬╜       ╬╬╣╣      ╙╝╣╣╬      ╙╣╣╣╗╖╓╗╣╣╣╜ ╟╣╣╬   ╣╣╣  ╣╣╣  ╟╣╣╦╓    ╣╣╣╣╣  
 ╙   ╓╦╖    ╬╬╣╣   ╓╗╗╖            ╙╝╣╣╣╣╝╜   ╘╝╝╜   ╝╝╝  ╝╝╝   ╙╣╣╣    ╟╣╣╣   
      ╙╬╬╬╬╬╬╬╣╣╣╣╣╣╝╜
          ╙╬╬╬╣╣╣╜
             ╙

 Version information:
  ml-agents: 1.0.0,
  ml-agents-envs: 1.0.0,
  Communicator API: 1.5.0,
  PyTorch: 2.3.1+cu121
D:\RocketProject\RocketProject\Rocket Project\venv\lib\site-packages\torch\__init__.py:749: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at ..\torch\csrc\tensor\python_tensor.cpp:433.)
  _C._set_default_tensor_type(t)
[INFO] Listening on port 5004. Start training by pressing the Play button in the Unity Editor.
[INFO] Learning was interrupted. Please wait while the graph is generated.
(venv) PS D:\RocketProject\RocketProject\Rocket Project> mlagents-learn config/config.yaml --run-id=translation4 --initialize-from=translation3 --torch-device="cuda" --force
D:\RocketProject\RocketProject\Rocket Project\venv\lib\site-packages\torch\__init__.py:749: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at ..\torch\csrc\tensor\python_tensor.cpp:433.)
  _C._set_default_tensor_type(t)

            ┐  ╖
        ╓╖╬│╡  ││╬╖╖
    ╓╖╬│││││┘  ╬│││││╬╖
 ╖╬│││││╬╜        ╙╬│││││╖╖                               ╗╗╗
 ╬╬╬╬╖││╦╖        ╖╬││╗╣╣╣╬      ╟╣╣╬    ╟╣╣╣             ╜╜╜  ╟╣╣
 ╬╬╬╬╬╬╬╬╖│╬╖╖╓╬╪│╓╣╣╣╣╣╣╣╬      ╟╣╣╬    ╟╣╣╣ ╒╣╣╖╗╣╣╣╗   ╣╣╣ ╣╣╣╣╣╣ ╟╣╣╖   ╣╣╣
 ╬╬╬╬┐  ╙╬╬╬╬│╓╣╣╣╝╜  ╫╣╣╣╬      ╟╣╣╬    ╟╣╣╣ ╟╣╣╣╙ ╙╣╣╣  ╣╣╣ ╙╟╣╣╜╙  ╫╣╣  ╟╣╣
 ╬╬╬╬┐     ╙╬╬╣╣      ╫╣╣╣╬      ╟╣╣╬    ╟╣╣╣ ╟╣╣╬   ╣╣╣  ╣╣╣  ╟╣╣     ╣╣╣┌╣╣╜
 ╬╬╬╜       ╬╬╣╣      ╙╝╣╣╬      ╙╣╣╣╗╖╓╗╣╣╣╜ ╟╣╣╬   ╣╣╣  ╣╣╣  ╟╣╣╦╓    ╣╣╣╣╣
 ╙   ╓╦╖    ╬╬╣╣   ╓╗╗╖            ╙╝╣╣╣╣╝╜   ╘╝╝╜   ╝╝╝  ╝╝╝   ╙╣╣╣    ╟╣╣╣
   ╩╬╬╬╬╬╬╦╦╬╬╣╣╗╣╣╣╣╣╣╣╝                                             ╫╣╣╣╣
      ╙╬╬╬╬╬╬╬╣╣╣╣╣╣╝╜
          ╙╬╬╬╣╣╣╜
             ╙

 Version information:
  ml-agents: 1.0.0,
  ml-agents-envs: 1.0.0,
  Communicator API: 1.5.0,
  PyTorch: 2.3.1+cu121
D:\RocketProject\RocketProject\Rocket Project\venv\lib\site-packages\torch\__init__.py:749: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at ..\torch\csrc\tensor\python_tensor.cpp:433.)
  _C._set_default_tensor_type(t)
[INFO] Listening on port 5004. Start training by pressing the Play button in the Unity Editor.
[INFO] Connected to Unity environment with package version 2.0.1 and communication version 1.5.0
[INFO] Connected new brain: RocketLanding?team=0
[INFO] Hyperparameters for behavior name RocketLanding: 
        trainer_type:   ppo
        hyperparameters:
          batch_size:   1024
          buffer_size:  20480
          learning_rate:        0.0003
          beta: 0.001
          epsilon:      0.2
          lambd:        0.95
          num_epoch:    3
          shared_critic:        False
          learning_rate_schedule:       linear
          beta_schedule:        linear
          epsilon_schedule:     linear
        checkpoint_interval:    500000
        network_settings:
          normalize:    True
          hidden_units: 1024
          num_layers:   5
          vis_encode_type:      simple
          memory:       None
          goal_conditioning_type:       hyper
          deterministic:        False
        reward_signals:
          extrinsic:
            gamma:      0.99
            strength:   1.0
            network_settings:
              normalize:        False
              hidden_units:     128
              num_layers:       2
              vis_encode_type:  simple
              memory:   None
              goal_conditioning_type:   hyper
              deterministic:    False
        init_path:      results\translation3\RocketLanding\checkpoint.pt
        keep_checkpoints:       5
        even_checkpoints:       False
        max_steps:      750000
        time_horizon:   128
        summary_freq:   20000
        threaded:       False
        self_play:      None
        behavioral_cloning:     None
[INFO] Initializing from results\translation3\RocketLanding\checkpoint.pt.
[INFO] Starting training from step 0 and saving to results\translation4\RocketLanding.
[INFO] RocketLanding. Step: 20000. Time Elapsed: 25.179 s. Mean Reward: 0.117. Std of Reward: 4.596. Training.
[INFO] RocketLanding. Step: 40000. Time Elapsed: 36.092 s. Mean Reward: 11.853. Std of Reward: 14.375. Training.
[INFO] RocketLanding. Step: 60000. Time Elapsed: 48.416 s. Mean Reward: 20.048. Std of Reward: 21.148. Training.
[INFO] RocketLanding. Step: 80000. Time Elapsed: 59.392 s. Mean Reward: 19.761. Std of Reward: 27.566. Training.
[INFO] RocketLanding. Step: 100000. Time Elapsed: 70.210 s. Mean Reward: 11.833. Std of Reward: 18.685. Training.
[INFO] RocketLanding. Step: 120000. Time Elapsed: 81.477 s. Mean Reward: 19.231. Std of Reward: 23.170. Training.
[INFO] RocketLanding. Step: 140000. Time Elapsed: 92.065 s. Mean Reward: 23.092. Std of Reward: 26.952. Training.
[INFO] RocketLanding. Step: 160000. Time Elapsed: 102.874 s. Mean Reward: 23.927. Std of Reward: 28.409. Training.
[INFO] RocketLanding. Step: 180000. Time Elapsed: 113.870 s. Mean Reward: 25.312. Std of Reward: 23.442. Training.
[INFO] RocketLanding. Step: 200000. Time Elapsed: 124.991 s. Mean Reward: 27.629. Std of Reward: 28.345. Training.
[INFO] RocketLanding. Step: 220000. Time Elapsed: 136.252 s. Mean Reward: 26.446. Std of Reward: 32.160. Training.
[INFO] RocketLanding. Step: 240000. Time Elapsed: 147.242 s. Mean Reward: 31.862. Std of Reward: 27.378. Training.
[INFO] RocketLanding. Step: 260000. Time Elapsed: 158.171 s. Mean Reward: 31.668. Std of Reward: 32.193. Training.
[INFO] RocketLanding. Step: 280000. Time Elapsed: 169.149 s. Mean Reward: 35.144. Std of Reward: 32.001. Training.
[INFO] RocketLanding. Step: 300000. Time Elapsed: 180.044 s. Mean Reward: 28.956. Std of Reward: 28.229. Training.
[INFO] RocketLanding. Step: 320000. Time Elapsed: 190.785 s. Mean Reward: 23.541. Std of Reward: 28.104. Training.
[INFO] RocketLanding. Step: 340000. Time Elapsed: 201.257 s. Mean Reward: 40.420. Std of Reward: 29.550. Training.
[INFO] RocketLanding. Step: 360000. Time Elapsed: 212.688 s. Mean Reward: 29.841. Std of Reward: 32.281. Training.
[INFO] RocketLanding. Step: 380000. Time Elapsed: 223.737 s. Mean Reward: 33.004. Std of Reward: 33.607. Training.
[INFO] RocketLanding. Step: 400000. Time Elapsed: 234.442 s. Mean Reward: 30.918. Std of Reward: 32.725. Training.
[INFO] RocketLanding. Step: 420000. Time Elapsed: 245.514 s. Mean Reward: 31.930. Std of Reward: 31.217. Training.
[INFO] RocketLanding. Step: 440000. Time Elapsed: 256.355 s. Mean Reward: 32.841. Std of Reward: 32.478. Training.
[INFO] RocketLanding. Step: 460000. Time Elapsed: 267.164 s. Mean Reward: 36.888. Std of Reward: 33.356. Training.
[INFO] RocketLanding. Step: 480000. Time Elapsed: 278.262 s. Mean Reward: 31.643. Std of Reward: 32.659. Training.
[INFO] RocketLanding. Step: 500000. Time Elapsed: 289.294 s. Mean Reward: 35.910. Std of Reward: 33.787. Training.
[INFO] Exported results\translation4\RocketLanding\RocketLanding-499963.onnx
[INFO] RocketLanding. Step: 520000. Time Elapsed: 300.440 s. Mean Reward: 40.344. Std of Reward: 34.888. Training.
[INFO] RocketLanding. Step: 540000. Time Elapsed: 311.476 s. Mean Reward: 48.351. Std of Reward: 32.733. Training.
[INFO] RocketLanding. Step: 560000. Time Elapsed: 322.360 s. Mean Reward: 42.297. Std of Reward: 32.475. Training.
[INFO] RocketLanding. Step: 580000. Time Elapsed: 333.688 s. Mean Reward: 42.193. Std of Reward: 35.044. Training.
[INFO] RocketLanding. Step: 600000. Time Elapsed: 344.158 s. Mean Reward: 47.487. Std of Reward: 31.441. Training.
[INFO] RocketLanding. Step: 620000. Time Elapsed: 353.004 s. Mean Reward: 38.826. Std of Reward: 34.299. Training.
[INFO] RocketLanding. Step: 640000. Time Elapsed: 363.367 s. Mean Reward: 39.827. Std of Reward: 34.252. Training.
[INFO] RocketLanding. Step: 660000. Time Elapsed: 375.256 s. Mean Reward: 38.897. Std of Reward: 33.183. Training.
[INFO] RocketLanding. Step: 680000. Time Elapsed: 385.708 s. Mean Reward: 38.789. Std of Reward: 35.249. Training.
[INFO] RocketLanding. Step: 700000. Time Elapsed: 396.904 s. Mean Reward: 38.191. Std of Reward: 34.931. Training.
[INFO] RocketLanding. Step: 720000. Time Elapsed: 407.829 s. Mean Reward: 37.594. Std of Reward: 32.541. Training.
[INFO] RocketLanding. Step: 740000. Time Elapsed: 419.184 s. Mean Reward: 35.793. Std of Reward: 33.407. Training.
[INFO] Exported results\translation4\RocketLanding\RocketLanding-750046.onnx
[INFO] Copied results\translation4\RocketLanding\RocketLanding-750046.onnx to results\translation4\RocketLanding.onnx.
D:\RocketProject\RocketProject\Rocket Project\venv\lib\site-packages\torch\__init__.py:749: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at ..\torch\csrc\tensor\python_tensor.cpp:433.)
  _C._set_default_tensor_type(t)

            ┐  ╖
        ╓╖╬│╡  ││╬╖╖
    ╓╖╬│││││┘  ╬│││││╬╖
 ╖╬│││││╬╜        ╙╬│││││╖╖                               ╗╗╗
 ╬╬╬╬╖││╦╖        ╖╬││╗╣╣╣╬      ╟╣╣╬    ╟╣╣╣             ╜╜╜  ╟╣╣
 ╬╬╬╬╬╬╬╬╖│╬╖╖╓╬╪│╓╣╣╣╣╣╣╣╬      ╟╣╣╬    ╟╣╣╣ ╒╣╣╖╗╣╣╣╗   ╣╣╣ ╣╣╣╣╣╣ ╟╣╣╖   ╣╣╣
 ╬╬╬╬┐  ╙╬╬╬╬│╓╣╣╣╝╜  ╫╣╣╣╬      ╟╣╣╬    ╟╣╣╣ ╟╣╣╣╙ ╙╣╣╣  ╣╣╣ ╙╟╣╣╜╙  ╫╣╣  ╟╣╣
 ╬╬╬╬┐     ╙╬╬╣╣      ╫╣╣╣╬      ╟╣╣╬    ╟╣╣╣ ╟╣╣╬   ╣╣╣  ╣╣╣  ╟╣╣     ╣╣╣┌╣╣╜
 ╬╬╬╜       ╬╬╣╣      ╙╝╣╣╬      ╙╣╣╣╗╖╓╗╣╣╣╜ ╟╣╣╬   ╣╣╣  ╣╣╣  ╟╣╣╦╓    ╣╣╣╣╣
 ╙   ╓╦╖    ╬╬╣╣   ╓╗╗╖            ╙╝╣╣╣╣╝╜   ╘╝╝╜   ╝╝╝  ╝╝╝   ╙╣╣╣    ╟╣╣╣
   ╩╬╬╬╬╬╬╦╦╬╬╣╣╗╣╣╣╣╣╣╣╝                                             ╫╣╣╣╣
      ╙╬╬╬╬╬╬╬╣╣╣╣╣╣╝╜
          ╙╬╬╬╣╣╣╜
             ╙

 Version information:
  ml-agents: 1.0.0,
  ml-agents-envs: 1.0.0,
  Communicator API: 1.5.0,
  PyTorch: 2.3.1+cu121
D:\RocketProject\RocketProject\Rocket Project\venv\lib\site-packages\torch\__init__.py:749: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at ..\torch\csrc\tensor\python_tensor.cpp:433.)
  _C._set_default_tensor_type(t)
[INFO] Listening on port 5004. Start training by pressing the Play button in the Unity Editor.
[INFO] Connected to Unity environment with package version 2.0.1 and communication version 1.5.0
[INFO] Connected new brain: RocketLanding?team=0
[INFO] Hyperparameters for behavior name RocketLanding: 
        trainer_type:   ppo
        hyperparameters:
          batch_size:   1024
          buffer_size:  20480
          learning_rate:        0.0003
          beta: 0.001
          epsilon:      0.2
          lambd:        0.95
          num_epoch:    3
          shared_critic:        False
          learning_rate_schedule:       linear
          beta_schedule:        linear
          epsilon_schedule:     linear
        checkpoint_interval:    500000
        network_settings:
          normalize:    True
          hidden_units: 1024
          num_layers:   5
          vis_encode_type:      simple
          memory:       None
          goal_conditioning_type:       hyper
          deterministic:        False
        reward_signals:
          extrinsic:
            gamma:      0.99
            strength:   1.0
            network_settings:
              normalize:        False
              hidden_units:     128
              num_layers:       2
              vis_encode_type:  simple
              memory:   None
              goal_conditioning_type:   hyper
              deterministic:    False
        init_path:      results\translation6\RocketLanding\checkpoint.pt
        keep_checkpoints:       5
        even_checkpoints:       False
        max_steps:      750000
        time_horizon:   128
        summary_freq:   20000
        threaded:       False
        self_play:      None
        behavioral_cloning:     None
[INFO] Initializing from results\translation6\RocketLanding\checkpoint.pt.
[INFO] Starting training from step 0 and saving to results\translation7\RocketLanding.
[INFO] RocketLanding. Step: 20000. Time Elapsed: 20.228 s. Mean Reward: -0.609. Std of Reward: 2.598. Training.
[INFO] RocketLanding. Step: 40000. Time Elapsed: 30.596 s. Mean Reward: 24.420. Std of Reward: 18.028. Training.
[INFO] RocketLanding. Step: 60000. Time Elapsed: 44.032 s. Mean Reward: 15.680. Std of Reward: 25.467. Training.
[INFO] RocketLanding. Step: 80000. Time Elapsed: 54.931 s. Mean Reward: 42.040. Std of Reward: 37.671. Training.
[INFO] RocketLanding. Step: 100000. Time Elapsed: 66.213 s. Mean Reward: 17.082. Std of Reward: 27.205. Training.
[INFO] RocketLanding. Step: 120000. Time Elapsed: 77.980 s. Mean Reward: 31.134. Std of Reward: 31.617. Training.
[INFO] RocketLanding. Step: 140000. Time Elapsed: 89.171 s. Mean Reward: 31.362. Std of Reward: 34.799. Training.
[INFO] RocketLanding. Step: 160000. Time Elapsed: 100.593 s. Mean Reward: 33.757. Std of Reward: 38.191. Training.
[INFO] RocketLanding. Step: 180000. Time Elapsed: 111.787 s. Mean Reward: 26.102. Std of Reward: 32.323. Training.
[INFO] RocketLanding. Step: 200000. Time Elapsed: 122.666 s. Mean Reward: 5.729. Std of Reward: 13.174. Training.
[INFO] RocketLanding. Step: 220000. Time Elapsed: 134.878 s. Mean Reward: 30.427. Std of Reward: 34.465. Training.
[INFO] RocketLanding. Step: 240000. Time Elapsed: 146.848 s. Mean Reward: 30.551. Std of Reward: 36.513. Training.
[INFO] RocketLanding. Step: 260000. Time Elapsed: 158.448 s. Mean Reward: 27.212. Std of Reward: 35.595. Training.
[INFO] RocketLanding. Step: 280000. Time Elapsed: 170.130 s. Mean Reward: 31.169. Std of Reward: 30.939. Training.
[INFO] RocketLanding. Step: 300000. Time Elapsed: 182.030 s. Mean Reward: 31.445. Std of Reward: 34.331. Training.
[INFO] RocketLanding. Step: 320000. Time Elapsed: 193.145 s. Mean Reward: 33.810. Std of Reward: 38.338. Training.
[INFO] RocketLanding. Step: 340000. Time Elapsed: 204.462 s. Mean Reward: 48.998. Std of Reward: 35.152. Training.
[INFO] RocketLanding. Step: 360000. Time Elapsed: 216.226 s. Mean Reward: 34.474. Std of Reward: 36.703. Training.
[INFO] RocketLanding. Step: 380000. Time Elapsed: 230.248 s. Mean Reward: 40.785. Std of Reward: 37.542. Training.
[INFO] RocketLanding. Step: 400000. Time Elapsed: 242.121 s. Mean Reward: 38.075. Std of Reward: 35.277. Training.
[INFO] RocketLanding. Step: 420000. Time Elapsed: 253.289 s. Mean Reward: 29.880. Std of Reward: 34.367. Training.
[INFO] RocketLanding. Step: 440000. Time Elapsed: 264.305 s. Mean Reward: 37.972. Std of Reward: 34.585. Training.
[INFO] RocketLanding. Step: 460000. Time Elapsed: 275.197 s. Mean Reward: 40.843. Std of Reward: 37.573. Training.
[INFO] RocketLanding. Step: 480000. Time Elapsed: 286.782 s. Mean Reward: 36.559. Std of Reward: 35.039. Training.
[INFO] RocketLanding. Step: 500000. Time Elapsed: 294.931 s. Mean Reward: 23.135. Std of Reward: 27.209. Training.
[INFO] Exported results\translation7\RocketLanding\RocketLanding-499876.onnx
[INFO] RocketLanding. Step: 520000. Time Elapsed: 306.633 s. Mean Reward: 29.260. Std of Reward: 37.239. Training.
[INFO] RocketLanding. Step: 540000. Time Elapsed: 317.283 s. Mean Reward: 30.494. Std of Reward: 34.833. Training.
[INFO] RocketLanding. Step: 560000. Time Elapsed: 328.283 s. Mean Reward: 34.391. Std of Reward: 35.647. Training.
[INFO] RocketLanding. Step: 580000. Time Elapsed: 339.138 s. Mean Reward: 30.266. Std of Reward: 35.802. Training.
[INFO] RocketLanding. Step: 600000. Time Elapsed: 350.102 s. Mean Reward: 47.822. Std of Reward: 33.419. Training.
[INFO] RocketLanding. Step: 620000. Time Elapsed: 361.729 s. Mean Reward: 37.673. Std of Reward: 37.239. Training.
[INFO] RocketLanding. Step: 640000. Time Elapsed: 372.632 s. Mean Reward: 39.063. Std of Reward: 35.218. Training.
[INFO] RocketLanding. Step: 660000. Time Elapsed: 384.321 s. Mean Reward: 34.824. Std of Reward: 37.514. Training.
[INFO] RocketLanding. Step: 680000. Time Elapsed: 395.056 s. Mean Reward: 31.099. Std of Reward: 36.957. Training.
[INFO] RocketLanding. Step: 700000. Time Elapsed: 405.730 s. Mean Reward: 39.006. Std of Reward: 35.870. Training.
[INFO] RocketLanding. Step: 720000. Time Elapsed: 416.424 s. Mean Reward: 39.706. Std of Reward: 35.036. Training.
[INFO] RocketLanding. Step: 740000. Time Elapsed: 427.046 s. Mean Reward: 36.921. Std of Reward: 37.923. Training.
[INFO] Exported results\translation7\RocketLanding\RocketLanding-750077.onnx
[INFO] Copied results\translation7\RocketLanding\RocketLanding-750077.onnx to results\translation7\RocketLanding.onnx.
(venv) PS D:\RocketProject\RocketProject\Rocket Project> 
D:\RocketProject\RocketProject\Rocket Project\venv\lib\site-packages\torch\__init__.py:749: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at ..\torch\csrc\tensor\python_tensor.cpp:433.)
  _C._set_default_tensor_type(t)

            ┐  ╖
        ╓╖╬│╡  ││╬╖╖
    ╓╖╬│││││┘  ╬│││││╬╖
 ╖╬│││││╬╜        ╙╬│││││╖╖                               ╗╗╗
 ╬╬╬╬╖││╦╖        ╖╬││╗╣╣╣╬      ╟╣╣╬    ╟╣╣╣             ╜╜╜  ╟╣╣
 ╬╬╬╬╬╬╬╬╖│╬╖╖╓╬╪│╓╣╣╣╣╣╣╣╬      ╟╣╣╬    ╟╣╣╣ ╒╣╣╖╗╣╣╣╗   ╣╣╣ ╣╣╣╣╣╣ ╟╣╣╖   ╣╣╣
 ╬╬╬╬┐  ╙╬╬╬╬│╓╣╣╣╝╜  ╫╣╣╣╬      ╟╣╣╬    ╟╣╣╣ ╟╣╣╣╙ ╙╣╣╣  ╣╣╣ ╙╟╣╣╜╙  ╫╣╣  ╟╣╣
 ╬╬╬╬┐     ╙╬╬╣╣      ╫╣╣╣╬      ╟╣╣╬    ╟╣╣╣ ╟╣╣╬   ╣╣╣  ╣╣╣  ╟╣╣     ╣╣╣┌╣╣╜
 ╬╬╬╜       ╬╬╣╣      ╙╝╣╣╬      ╙╣╣╣╗╖╓╗╣╣╣╜ ╟╣╣╬   ╣╣╣  ╣╣╣  ╟╣╣╦╓    ╣╣╣╣╣
 ╙   ╓╦╖    ╬╬╣╣   ╓╗╗╖            ╙╝╣╣╣╣╝╜   ╘╝╝╜   ╝╝╝  ╝╝╝   ╙╣╣╣    ╟╣╣╣
   ╩╬╬╬╬╬╬╦╦╬╬╣╣╗╣╣╣╣╣╣╣╝                                             ╫╣╣╣╣
      ╙╬╬╬╬╬╬╬╣╣╣╣╣╣╝╜
          ╙╬╬╬╣╣╣╜
             ╙

 Version information:
  ml-agents: 1.0.0,
  ml-agents-envs: 1.0.0,
  Communicator API: 1.5.0,
  PyTorch: 2.3.1+cu121
D:\RocketProject\RocketProject\Rocket Project\venv\lib\site-packages\torch\__init__.py:749: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at ..\torch\csrc\tensor\python_tensor.cpp:433.)
  _C._set_default_tensor_type(t)
[INFO] Listening on port 5004. Start training by pressing the Play button in the Unity Editor.
[INFO] Connected to Unity environment with package version 2.0.1 and communication version 1.5.0
[INFO] Connected new brain: RocketLanding?team=0
[WARNING] Deleting TensorBoard data events.out.tfevents.1737073247.DESKTOP-9BP097D.1264.0 that was left over from a previous run.
[INFO] Hyperparameters for behavior name RocketLanding:
        trainer_type:   ppo
        hyperparameters:
          batch_size:   1024
          buffer_size:  20480
          learning_rate:        0.0003
          beta: 0.001
          epsilon:      0.2
          lambd:        0.95
          num_epoch:    3
          shared_critic:        False
          learning_rate_schedule:       linear
          beta_schedule:        linear
          epsilon_schedule:     linear
        checkpoint_interval:    500000
        network_settings:
          normalize:    True
          hidden_units: 1024
          num_layers:   5
          vis_encode_type:      simple
          memory:       None
          goal_conditioning_type:       hyper
          deterministic:        False
        reward_signals:
          extrinsic:
            gamma:      0.99
            strength:   1.0
            network_settings:
              normalize:        False
              hidden_units:     128
              num_layers:       2
              vis_encode_type:  simple
              memory:   None
              goal_conditioning_type:   hyper
              deterministic:    False
        init_path:      results\translation7\RocketLanding\checkpoint.pt
        keep_checkpoints:       5
        even_checkpoints:       False
        max_steps:      750000
        time_horizon:   128
        summary_freq:   20000
        threaded:       False
        self_play:      None
        behavioral_cloning:     None
[INFO] Initializing from results\translation7\RocketLanding\checkpoint.pt.
[INFO] Starting training from step 0 and saving to results\translation8\RocketLanding.
[INFO] RocketLanding. Step: 20000. Time Elapsed: 16.521 s. Mean Reward: -26.164. Std of Reward: 22.120. Training.
[INFO] RocketLanding. Step: 40000. Time Elapsed: 26.659 s. Mean Reward: 20.104. Std of Reward: 0.000. Training.
[INFO] RocketLanding. Step: 60000. Time Elapsed: 39.549 s. Mean Reward: 23.308. Std of Reward: 21.640. Training.
[INFO] RocketLanding. Step: 80000. Time Elapsed: 50.727 s. Mean Reward: -15.610. Std of Reward: 80.139. Training.
[INFO] RocketLanding. Step: 100000. Time Elapsed: 62.151 s. Mean Reward: -38.452. Std of Reward: 66.502. Training.
[INFO] RocketLanding. Step: 120000. Time Elapsed: 73.486 s. Mean Reward: -56.628. Std of Reward: 109.094. Training.
[INFO] RocketLanding. Step: 140000. Time Elapsed: 84.361 s. Mean Reward: -96.845. Std of Reward: 168.636. Training.
[INFO] RocketLanding. Step: 160000. Time Elapsed: 95.645 s. Mean Reward: -99.225. Std of Reward: 154.465. Training.
[INFO] RocketLanding. Step: 180000. Time Elapsed: 107.078 s. Mean Reward: -59.374. Std of Reward: 125.327. Training.
[INFO] RocketLanding. Step: 200000. Time Elapsed: 117.958 s. Mean Reward: -76.326. Std of Reward: 73.831. Training.
[INFO] RocketLanding. Step: 220000. Time Elapsed: 129.783 s. Mean Reward: -87.716. Std of Reward: 97.021. Training.
[INFO] RocketLanding. Step: 240000. Time Elapsed: 140.851 s. Mean Reward: -60.457. Std of Reward: 97.549. Training.
[INFO] RocketLanding. Step: 260000. Time Elapsed: 152.031 s. Mean Reward: 5.669. Std of Reward: 65.942. Training.
[INFO] RocketLanding. Step: 280000. Time Elapsed: 163.154 s. Mean Reward: -23.481. Std of Reward: 65.667. Training.
[INFO] RocketLanding. Step: 300000. Time Elapsed: 174.180 s. Mean Reward: -108.921. Std of Reward: 171.292. Training.
[INFO] RocketLanding. Step: 320000. Time Elapsed: 184.949 s. Mean Reward: -44.042. Std of Reward: 137.520. Training.
[INFO] RocketLanding. Step: 340000. Time Elapsed: 193.057 s. Mean Reward: -79.728. Std of Reward: 110.705. Training.
[INFO] RocketLanding. Step: 360000. Time Elapsed: 204.033 s. Mean Reward: -78.247. Std of Reward: 123.610. Training.
[INFO] RocketLanding. Step: 380000. Time Elapsed: 215.134 s. Mean Reward: -62.189. Std of Reward: 102.410. Training.
[INFO] RocketLanding. Step: 400000. Time Elapsed: 226.544 s. Mean Reward: -38.756. Std of Reward: 114.191. Training.
[INFO] RocketLanding. Step: 420000. Time Elapsed: 237.698 s. Mean Reward: -30.886. Std of Reward: 70.395. Training.
[INFO] RocketLanding. Step: 440000. Time Elapsed: 248.228 s. Mean Reward: -71.400. Std of Reward: 146.830. Training.
[INFO] RocketLanding. Step: 460000. Time Elapsed: 259.420 s. Mean Reward: -12.255. Std of Reward: 65.406. Training.
[INFO] RocketLanding. Step: 480000. Time Elapsed: 270.082 s. Mean Reward: -7.265. Std of Reward: 48.884. Training.
[INFO] RocketLanding. Step: 500000. Time Elapsed: 281.060 s. Mean Reward: 10.489. Std of Reward: 51.434. Training.
[INFO] Exported results\translation8\RocketLanding\RocketLanding-499940.onnx
[INFO] RocketLanding. Step: 520000. Time Elapsed: 292.371 s. Mean Reward: -22.084. Std of Reward: 81.163. Training.
[INFO] RocketLanding. Step: 540000. Time Elapsed: 303.444 s. Mean Reward: 5.167. Std of Reward: 73.691. Training.
[INFO] RocketLanding. Step: 560000. Time Elapsed: 314.492 s. Mean Reward: -31.072. Std of Reward: 127.207. Training.
[INFO] RocketLanding. Step: 580000. Time Elapsed: 325.451 s. Mean Reward: 18.736. Std of Reward: 41.841. Training.
[INFO] RocketLanding. Step: 600000. Time Elapsed: 337.528 s. Mean Reward: 3.631. Std of Reward: 54.945. Training.
[INFO] RocketLanding. Step: 620000. Time Elapsed: 348.498 s. Mean Reward: 11.442. Std of Reward: 46.319. Training.
[INFO] RocketLanding. Step: 640000. Time Elapsed: 360.362 s. Mean Reward: -8.770. Std of Reward: 93.638. Training.
[INFO] RocketLanding. Step: 660000. Time Elapsed: 372.170 s. Mean Reward: 19.276. Std of Reward: 50.480. Training.
[INFO] RocketLanding. Step: 680000. Time Elapsed: 383.743 s. Mean Reward: 27.167. Std of Reward: 39.344. Training.
[INFO] RocketLanding. Step: 700000. Time Elapsed: 394.853 s. Mean Reward: 17.152. Std of Reward: 42.784. Training.
[INFO] RocketLanding. Step: 720000. Time Elapsed: 406.465 s. Mean Reward: 32.400. Std of Reward: 30.756. Training.
[INFO] RocketLanding. Step: 740000. Time Elapsed: 417.678 s. Mean Reward: 18.675. Std of Reward: 35.633. Training.
[INFO] Exported results\translation8\RocketLanding\RocketLanding-750104.onnx
[INFO] Copied results\translation8\RocketLanding\RocketLanding-750104.onnx to results\translation8\RocketLanding.onnx.
(venv) PS D:\RocketProject\RocketProject\Rocket Project> 
D:\RocketProject\RocketProject\Rocket Project\venv\lib\site-packages\torch\__init__.py:749: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at ..\torch\csrc\tensor\python_tensor.cpp:433.)
  _C._set_default_tensor_type(t)

            ┐  ╖
        ╓╖╬│╡  ││╬╖╖
    ╓╖╬│││││┘  ╬│││││╬╖
 ╖╬│││││╬╜        ╙╬│││││╖╖                               ╗╗╗
 ╬╬╬╬╖││╦╖        ╖╬││╗╣╣╣╬      ╟╣╣╬    ╟╣╣╣             ╜╜╜  ╟╣╣
 ╬╬╬╬╬╬╬╬╖│╬╖╖╓╬╪│╓╣╣╣╣╣╣╣╬      ╟╣╣╬    ╟╣╣╣ ╒╣╣╖╗╣╣╣╗   ╣╣╣ ╣╣╣╣╣╣ ╟╣╣╖   ╣╣╣
 ╬╬╬╬┐  ╙╬╬╬╬│╓╣╣╣╝╜  ╫╣╣╣╬      ╟╣╣╬    ╟╣╣╣ ╟╣╣╣╙ ╙╣╣╣  ╣╣╣ ╙╟╣╣╜╙  ╫╣╣  ╟╣╣
 ╬╬╬╬┐     ╙╬╬╣╣      ╫╣╣╣╬      ╟╣╣╬    ╟╣╣╣ ╟╣╣╬   ╣╣╣  ╣╣╣  ╟╣╣     ╣╣╣┌╣╣╜
 ╬╬╬╜       ╬╬╣╣      ╙╝╣╣╬      ╙╣╣╣╗╖╓╗╣╣╣╜ ╟╣╣╬   ╣╣╣  ╣╣╣  ╟╣╣╦╓    ╣╣╣╣╣
 ╙   ╓╦╖    ╬╬╣╣   ╓╗╗╖            ╙╝╣╣╣╣╝╜   ╘╝╝╜   ╝╝╝  ╝╝╝   ╙╣╣╣    ╟╣╣╣
   ╩╬╬╬╬╬╬╦╦╬╬╣╣╗╣╣╣╣╣╣╣╝                                             ╫╣╣╣╣
      ╙╬╬╬╬╬╬╬╣╣╣╣╣╣╝╜
          ╙╬╬╬╣╣╣╜
             ╙

 Version information:
  ml-agents: 1.0.0,
  ml-agents-envs: 1.0.0,
  Communicator API: 1.5.0,
  PyTorch: 2.3.1+cu121
D:\RocketProject\RocketProject\Rocket Project\venv\lib\site-packages\torch\__init__.py:749: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at ..\torch\csrc\tensor\python_tensor.cpp:433.)
  _C._set_default_tensor_type(t)
[INFO] Listening on port 5004. Start training by pressing the Play button in the Unity Editor.
[INFO] Connected to Unity environment with package version 2.0.1 and communication version 1.5.0
[INFO] Connected new brain: RocketLanding?team=0
[INFO] Hyperparameters for behavior name RocketLanding: 
        trainer_type:   ppo
        hyperparameters:
          batch_size:   1024
          buffer_size:  20480
          learning_rate:        0.0003
          beta: 0.001
          epsilon:      0.2
          lambd:        0.95
          num_epoch:    3
          shared_critic:        False
          learning_rate_schedule:       linear
          beta_schedule:        linear
          epsilon_schedule:     linear
        checkpoint_interval:    500000
        network_settings:
          normalize:    True
          hidden_units: 1024
          num_layers:   5
          vis_encode_type:      simple
          memory:       None
          goal_conditioning_type:       hyper
          deterministic:        False
        reward_signals:
          extrinsic:
            gamma:      0.99
            strength:   1.0
            network_settings:
              normalize:        False
              hidden_units:     128
              num_layers:       2
              vis_encode_type:  simple
              memory:   None
              goal_conditioning_type:   hyper
              deterministic:    False
        init_path:      results\translation8\RocketLanding\checkpoint.pt
        keep_checkpoints:       5
        even_checkpoints:       False
        max_steps:      750000
        time_horizon:   128
        summary_freq:   20000
        threaded:       False
        self_play:      None
        behavioral_cloning:     None
[INFO] Initializing from results\translation8\RocketLanding\checkpoint.pt.
[INFO] Starting training from step 0 and saving to results\translation9\RocketLanding.
[INFO] RocketLanding. Step: 20000. Time Elapsed: 18.888 s. Mean Reward: -14.661. Std of Reward: 20.858. Training.
[INFO] RocketLanding. Step: 40000. Time Elapsed: 30.944 s. Mean Reward: -44.764. Std of Reward: 30.830. Training.
[INFO] RocketLanding. Step: 60000. Time Elapsed: 39.023 s. Mean Reward: -53.463. Std of Reward: 0.000. Training.
[INFO] RocketLanding. Step: 80000. Time Elapsed: 50.998 s. Mean Reward: -15.643. Std of Reward: 53.225. Training.
[INFO] RocketLanding. Step: 100000. Time Elapsed: 61.941 s. Mean Reward: -3.791. Std of Reward: 70.386. Training.
[INFO] RocketLanding. Step: 120000. Time Elapsed: 71.395 s. Mean Reward: 17.576. Std of Reward: 47.863. Training.
[INFO] RocketLanding. Step: 140000. Time Elapsed: 81.308 s. Mean Reward: 7.276. Std of Reward: 32.222. Training.
[INFO] RocketLanding. Step: 160000. Time Elapsed: 91.540 s. Mean Reward: -1.429. Std of Reward: 33.243. Training.
[INFO] RocketLanding. Step: 180000. Time Elapsed: 100.552 s. Mean Reward: 5.252. Std of Reward: 22.499. Training.
[INFO] RocketLanding. Step: 200000. Time Elapsed: 110.813 s. Mean Reward: 9.359. Std of Reward: 34.988. Training.
[INFO] RocketLanding. Step: 220000. Time Elapsed: 120.153 s. Mean Reward: 3.065. Std of Reward: 58.008. Training.
[INFO] RocketLanding. Step: 240000. Time Elapsed: 127.388 s. Mean Reward: 9.110. Std of Reward: 45.437. Training.
[INFO] RocketLanding. Step: 260000. Time Elapsed: 137.057 s. Mean Reward: -11.690. Std of Reward: 61.498. Training.
[INFO] RocketLanding. Step: 280000. Time Elapsed: 147.774 s. Mean Reward: 5.723. Std of Reward: 51.524. Training.
[INFO] RocketLanding. Step: 300000. Time Elapsed: 157.759 s. Mean Reward: 3.483. Std of Reward: 56.805. Training.
[INFO] RocketLanding. Step: 320000. Time Elapsed: 167.343 s. Mean Reward: 5.534. Std of Reward: 72.357. Training.
[INFO] RocketLanding. Step: 340000. Time Elapsed: 177.283 s. Mean Reward: -2.032. Std of Reward: 64.793. Training.
[INFO] RocketLanding. Step: 360000. Time Elapsed: 186.938 s. Mean Reward: 22.419. Std of Reward: 19.831. Training.
[INFO] RocketLanding. Step: 380000. Time Elapsed: 196.259 s. Mean Reward: -11.752. Std of Reward: 45.241. Training.
[INFO] RocketLanding. Step: 400000. Time Elapsed: 205.595 s. Mean Reward: 8.973. Std of Reward: 58.196. Training.
[INFO] RocketLanding. Step: 420000. Time Elapsed: 215.164 s. Mean Reward: 7.749. Std of Reward: 50.088. Training.
[INFO] RocketLanding. Step: 440000. Time Elapsed: 224.540 s. Mean Reward: -13.315. Std of Reward: 58.612. Training.
[INFO] RocketLanding. Step: 460000. Time Elapsed: 234.066 s. Mean Reward: 20.835. Std of Reward: 44.170. Training.
[INFO] RocketLanding. Step: 480000. Time Elapsed: 243.403 s. Mean Reward: 6.967. Std of Reward: 45.596. Training.
[INFO] RocketLanding. Step: 500000. Time Elapsed: 252.915 s. Mean Reward: 22.497. Std of Reward: 44.564. Training.
[INFO] Exported results\translation9\RocketLanding\RocketLanding-499876.onnx
[INFO] RocketLanding. Step: 520000. Time Elapsed: 263.017 s. Mean Reward: 21.182. Std of Reward: 41.003. Training.
[INFO] RocketLanding. Step: 540000. Time Elapsed: 272.620 s. Mean Reward: 5.608. Std of Reward: 41.773. Training.
[INFO] RocketLanding. Step: 560000. Time Elapsed: 281.870 s. Mean Reward: 9.271. Std of Reward: 29.020. Training.
[INFO] RocketLanding. Step: 580000. Time Elapsed: 291.675 s. Mean Reward: -3.184. Std of Reward: 70.001. Training.
[INFO] RocketLanding. Step: 600000. Time Elapsed: 300.759 s. Mean Reward: 16.944. Std of Reward: 33.274. Training.
[INFO] RocketLanding. Step: 620000. Time Elapsed: 310.461 s. Mean Reward: 29.974. Std of Reward: 32.223. Training.
[INFO] RocketLanding. Step: 640000. Time Elapsed: 319.889 s. Mean Reward: 9.360. Std of Reward: 32.918. Training.
[INFO] RocketLanding. Step: 660000. Time Elapsed: 329.187 s. Mean Reward: 3.138. Std of Reward: 44.653. Training.
[INFO] RocketLanding. Step: 680000. Time Elapsed: 338.905 s. Mean Reward: 7.821. Std of Reward: 45.576. Training.
[INFO] RocketLanding. Step: 700000. Time Elapsed: 348.504 s. Mean Reward: 10.404. Std of Reward: 46.558. Training.
[INFO] RocketLanding. Step: 720000. Time Elapsed: 357.780 s. Mean Reward: 10.501. Std of Reward: 45.427. Training.
[INFO] RocketLanding. Step: 740000. Time Elapsed: 367.330 s. Mean Reward: 19.238. Std of Reward: 52.928. Training.
[INFO] Exported results\translation9\RocketLanding\RocketLanding-750044.onnx
[INFO] Copied results\translation9\RocketLanding\RocketLanding-750044.onnx to results\translation9\RocketLanding.onnx.
(venv) PS D:\RocketProject\RocketProject\Rocket Project> 
D:\RocketProject\RocketProject\Rocket Project\venv\lib\site-packages\torch\__init__.py:749: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at ..\torch\csrc\tensor\python_tensor.cpp:433.)
  _C._set_default_tensor_type(t)

            ┐  ╖
        ╓╖╬│╡  ││╬╖╖
    ╓╖╬│││││┘  ╬│││││╬╖
 ╖╬│││││╬╜        ╙╬│││││╖╖                               ╗╗╗
 ╬╬╬╬╖││╦╖        ╖╬││╗╣╣╣╬      ╟╣╣╬    ╟╣╣╣             ╜╜╜  ╟╣╣
 ╬╬╬╬╬╬╬╬╖│╬╖╖╓╬╪│╓╣╣╣╣╣╣╣╬      ╟╣╣╬    ╟╣╣╣ ╒╣╣╖╗╣╣╣╗   ╣╣╣ ╣╣╣╣╣╣ ╟╣╣╖   ╣╣╣
 ╬╬╬╬┐  ╙╬╬╬╬│╓╣╣╣╝╜  ╫╣╣╣╬      ╟╣╣╬    ╟╣╣╣ ╟╣╣╣╙ ╙╣╣╣  ╣╣╣ ╙╟╣╣╜╙  ╫╣╣  ╟╣╣
 ╬╬╬╬┐     ╙╬╬╣╣      ╫╣╣╣╬      ╟╣╣╬    ╟╣╣╣ ╟╣╣╬   ╣╣╣  ╣╣╣  ╟╣╣     ╣╣╣┌╣╣╜
 ╬╬╬╜       ╬╬╣╣      ╙╝╣╣╬      ╙╣╣╣╗╖╓╗╣╣╣╜ ╟╣╣╬   ╣╣╣  ╣╣╣  ╟╣╣╦╓    ╣╣╣╣╣
 ╙   ╓╦╖    ╬╬╣╣   ╓╗╗╖            ╙╝╣╣╣╣╝╜   ╘╝╝╜   ╝╝╝  ╝╝╝   ╙╣╣╣    ╟╣╣╣
   ╩╬╬╬╬╬╬╦╦╬╬╣╣╗╣╣╣╣╣╣╣╝                                             ╫╣╣╣╣
      ╙╬╬╬╬╬╬╬╣╣╣╣╣╣╝╜
          ╙╬╬╬╣╣╣╜
             ╙

 Version information:
  ml-agents: 1.0.0,
  ml-agents-envs: 1.0.0,
  Communicator API: 1.5.0,
  PyTorch: 2.3.1+cu121
D:\RocketProject\RocketProject\Rocket Project\venv\lib\site-packages\torch\__init__.py:749: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at ..\torch\csrc\tensor\python_tensor.cpp:433.)
  _C._set_default_tensor_type(t)
[INFO] Listening on port 5004. Start training by pressing the Play button in the Unity Editor.
[INFO] Connected to Unity environment with package version 2.0.1 and communication version 1.5.0
[INFO] Connected new brain: RocketLanding?team=0
[WARNING] Deleting TensorBoard data events.out.tfevents.1737078444.DESKTOP-9BP097D.34588.0 that was left over from a previous run.
[INFO] Hyperparameters for behavior name RocketLanding:
        trainer_type:   ppo
        hyperparameters:
          batch_size:   1024
          buffer_size:  20480
          learning_rate:        0.0003
          beta: 0.001
          epsilon:      0.2
          lambd:        0.95
          num_epoch:    3
          shared_critic:        False
          learning_rate_schedule:       linear
          beta_schedule:        linear
          epsilon_schedule:     linear
        checkpoint_interval:    500000
        network_settings:
          normalize:    True
          hidden_units: 1024
          num_layers:   5
          vis_encode_type:      simple
          memory:       None
          goal_conditioning_type:       hyper
          deterministic:        False
        reward_signals:
          extrinsic:
            gamma:      0.99
            strength:   1.0
            network_settings:
              normalize:        False
              hidden_units:     128
              num_layers:       2
              vis_encode_type:  simple
              memory:   None
              goal_conditioning_type:   hyper
              deterministic:    False
        init_path:      results\translation11\RocketLanding\checkpoint.pt
        keep_checkpoints:       5
        even_checkpoints:       False
        max_steps:      750000
        time_horizon:   128
        summary_freq:   20000
        threaded:       False
        self_play:      None
        behavioral_cloning:     None
[INFO] Initializing from results\translation11\RocketLanding\checkpoint.pt.
[INFO] Starting training from step 0 and saving to results\translation12\RocketLanding.
[INFO] RocketLanding. Step: 20000. Time Elapsed: 22.489 s. Mean Reward: 2.407. Std of Reward: 5.233. Training.
[INFO] RocketLanding. Step: 40000. Time Elapsed: 32.512 s. Mean Reward: 11.943. Std of Reward: 3.878. Training.
[INFO] RocketLanding. Step: 60000. Time Elapsed: 37.626 s. Mean Reward: 18.764. Std of Reward: 12.478. Training.
[INFO] RocketLanding. Step: 80000. Time Elapsed: 47.814 s. Mean Reward: 35.296. Std of Reward: 13.630. Training.
[INFO] RocketLanding. Step: 100000. Time Elapsed: 58.236 s. Mean Reward: 50.718. Std of Reward: 47.425. Training.
[INFO] RocketLanding. Step: 120000. Time Elapsed: 68.977 s. Mean Reward: 54.003. Std of Reward: 38.055. Training.
[INFO] RocketLanding. Step: 140000. Time Elapsed: 77.670 s. Mean Reward: 61.269. Std of Reward: 30.255. Training.
[INFO] RocketLanding. Step: 160000. Time Elapsed: 87.333 s. Mean Reward: 55.531. Std of Reward: 17.294. Training.
[INFO] RocketLanding. Step: 180000. Time Elapsed: 96.869 s. Mean Reward: 47.395. Std of Reward: 20.881. Training.
[INFO] RocketLanding. Step: 200000. Time Elapsed: 106.322 s. Mean Reward: 64.977. Std of Reward: 34.939. Training.
[INFO] RocketLanding. Step: 220000. Time Elapsed: 115.890 s. Mean Reward: 39.315. Std of Reward: 18.301. Training.
[INFO] RocketLanding. Step: 240000. Time Elapsed: 125.228 s. Mean Reward: 42.687. Std of Reward: 18.768. Training.
[INFO] RocketLanding. Step: 260000. Time Elapsed: 134.800 s. Mean Reward: 61.918. Std of Reward: 30.618. Training.
[INFO] RocketLanding. Step: 280000. Time Elapsed: 144.210 s. Mean Reward: 56.301. Std of Reward: 15.690. Training.
[INFO] RocketLanding. Step: 300000. Time Elapsed: 154.652 s. Mean Reward: 53.752. Std of Reward: 12.349. Training.
[INFO] RocketLanding. Step: 320000. Time Elapsed: 164.448 s. Mean Reward: 61.164. Std of Reward: 39.428. Training.
[INFO] RocketLanding. Step: 340000. Time Elapsed: 174.204 s. Mean Reward: 53.964. Std of Reward: 39.080. Training.
[INFO] RocketLanding. Step: 360000. Time Elapsed: 183.768 s. Mean Reward: 51.932. Std of Reward: 14.801. Training.
[INFO] RocketLanding. Step: 380000. Time Elapsed: 193.966 s. Mean Reward: 59.799. Std of Reward: 39.348. Training.
[INFO] RocketLanding. Step: 400000. Time Elapsed: 203.297 s. Mean Reward: 48.512. Std of Reward: 22.009. Training.
[INFO] RocketLanding. Step: 420000. Time Elapsed: 209.892 s. Mean Reward: 57.539. Std of Reward: 25.037. Training.
[INFO] RocketLanding. Step: 440000. Time Elapsed: 219.356 s. Mean Reward: 57.987. Std of Reward: 9.735. Training.
[INFO] RocketLanding. Step: 460000. Time Elapsed: 229.502 s. Mean Reward: 54.410. Std of Reward: 13.339. Training.
[INFO] RocketLanding. Step: 480000. Time Elapsed: 238.968 s. Mean Reward: 54.007. Std of Reward: 18.508. Training.
[INFO] RocketLanding. Step: 500000. Time Elapsed: 248.214 s. Mean Reward: 63.755. Std of Reward: 35.952. Training.
[INFO] Exported results\translation12\RocketLanding\RocketLanding-499990.onnx
[INFO] RocketLanding. Step: 520000. Time Elapsed: 258.001 s. Mean Reward: 34.381. Std of Reward: 11.437. Training.
[INFO] RocketLanding. Step: 540000. Time Elapsed: 267.391 s. Mean Reward: 48.410. Std of Reward: 17.552. Training.
[INFO] RocketLanding. Step: 560000. Time Elapsed: 276.487 s. Mean Reward: 47.001. Std of Reward: 15.405. Training.
[INFO] RocketLanding. Step: 580000. Time Elapsed: 285.417 s. Mean Reward: 59.653. Std of Reward: 26.126. Training.
[INFO] RocketLanding. Step: 600000. Time Elapsed: 294.299 s. Mean Reward: 59.079. Std of Reward: 26.235. Training.
[INFO] RocketLanding. Step: 620000. Time Elapsed: 303.258 s. Mean Reward: 56.900. Std of Reward: 39.143. Training.
[INFO] RocketLanding. Step: 640000. Time Elapsed: 311.828 s. Mean Reward: 42.134. Std of Reward: 13.743. Training.
[INFO] RocketLanding. Step: 660000. Time Elapsed: 320.785 s. Mean Reward: 61.580. Std of Reward: 31.879. Training.
[INFO] RocketLanding. Step: 680000. Time Elapsed: 329.997 s. Mean Reward: 52.351. Std of Reward: 12.312. Training.
[INFO] RocketLanding. Step: 700000. Time Elapsed: 338.811 s. Mean Reward: 61.344. Std of Reward: 21.534. Training.
[INFO] RocketLanding. Step: 720000. Time Elapsed: 347.751 s. Mean Reward: 56.420. Std of Reward: 14.957. Training.
[INFO] RocketLanding. Step: 740000. Time Elapsed: 356.788 s. Mean Reward: 58.182. Std of Reward: 28.555. Training.
[WARNING] Restarting worker[0] after 'Communicator has exited.'
D:\RocketProject\RocketProject\Rocket Project\venv\lib\site-packages\torch\__init__.py:749: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at ..\torch\csrc\tensor\python_tensor.cpp:433.)
  _C._set_default_tensor_type(t)
[INFO] Listening on port 5004. Start training by pressing the Play button in the Unity Editor.

# (2/13/25) TRANSLATION 18: added more changes to the reward values and a new demo
