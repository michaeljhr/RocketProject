{
    "name": "root",
    "gauges": {
        "RocketLanding.Policy.Entropy.mean": {
            "value": 1.5831962823867798,
            "min": 1.4345552921295166,
            "max": 1.5831962823867798,
            "count": 10
        },
        "RocketLanding.Policy.Entropy.sum": {
            "value": 79539.78125,
            "min": 72439.3046875,
            "max": 79539.78125,
            "count": 10
        },
        "RocketLanding.Environment.EpisodeLength.mean": {
            "value": 117.81882352941176,
            "min": 113.58564814814815,
            "max": 117.86052009456264,
            "count": 10
        },
        "RocketLanding.Environment.EpisodeLength.sum": {
            "value": 50073.0,
            "min": 48996.0,
            "max": 50194.0,
            "count": 10
        },
        "RocketLanding.Step.mean": {
            "value": 499998.0,
            "min": 49949.0,
            "max": 499998.0,
            "count": 10
        },
        "RocketLanding.Step.sum": {
            "value": 499998.0,
            "min": 49949.0,
            "max": 499998.0,
            "count": 10
        },
        "RocketLanding.Policy.ExtrinsicValueEstimate.mean": {
            "value": -640.968994140625,
            "min": -736.6383666992188,
            "max": 102446.5234375,
            "count": 10
        },
        "RocketLanding.Policy.ExtrinsicValueEstimate.sum": {
            "value": -540336.875,
            "min": -620249.5,
            "max": 87591776.0,
            "count": 10
        },
        "RocketLanding.Environment.CumulativeReward.mean": {
            "value": -26.181672069325167,
            "min": -26.38482799782203,
            "max": -25.663954587909284,
            "count": 10
        },
        "RocketLanding.Environment.CumulativeReward.sum": {
            "value": -11127.210629463196,
            "min": -11127.210629463196,
            "max": -10830.188836097717,
            "count": 10
        },
        "RocketLanding.Policy.ExtrinsicReward.mean": {
            "value": -26.181672069325167,
            "min": -26.38482799782203,
            "max": -25.663954587909284,
            "count": 10
        },
        "RocketLanding.Policy.ExtrinsicReward.sum": {
            "value": -11127.210629463196,
            "min": -11127.210629463196,
            "max": -10830.188836097717,
            "count": 10
        },
        "RocketLanding.Losses.PolicyLoss.mean": {
            "value": 0.048162029822900264,
            "min": 0.04363452236012866,
            "max": 0.05252751894404355,
            "count": 10
        },
        "RocketLanding.Losses.PolicyLoss.sum": {
            "value": 0.24081014911450133,
            "min": 0.1806044595626493,
            "max": 0.24081014911450133,
            "count": 10
        },
        "RocketLanding.Losses.ValueLoss.mean": {
            "value": 613676.4056249999,
            "min": 613676.4056249999,
            "max": 769737409.6,
            "count": 10
        },
        "RocketLanding.Losses.ValueLoss.sum": {
            "value": 3068382.0281249997,
            "min": 2736710.395833333,
            "max": 3078949638.4,
            "count": 10
        },
        "RocketLanding.Policy.LearningRate.mean": {
            "value": 1.6330654556479996e-05,
            "min": 1.6330654556479996e-05,
            "max": 0.00028452855515714994,
            "count": 10
        },
        "RocketLanding.Policy.LearningRate.sum": {
            "value": 8.165327278239998e-05,
            "min": 8.165327278239998e-05,
            "max": 0.0012838110720629996,
            "count": 10
        },
        "RocketLanding.Policy.Epsilon.mean": {
            "value": 0.10544351999999999,
            "min": 0.10544351999999999,
            "max": 0.19484285000000007,
            "count": 10
        },
        "RocketLanding.Policy.Epsilon.sum": {
            "value": 0.5272176,
            "min": 0.49988180000000004,
            "max": 0.9279369999999998,
            "count": 10
        },
        "RocketLanding.Policy.Beta.mean": {
            "value": 0.000281631648,
            "min": 0.000281631648,
            "max": 0.004742658215000001,
            "count": 10
        },
        "RocketLanding.Policy.Beta.sum": {
            "value": 0.00140815824,
            "min": 0.00140815824,
            "max": 0.021404056299999995,
            "count": 10
        },
        "RocketLanding.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 10
        },
        "RocketLanding.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 10
        }
    },
    "metadata": {
        "timer_format_version": "0.1.0",
        "start_time_seconds": "1724979122",
        "python_version": "3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]",
        "command_line_arguments": "D:\\RocketProject\\RocketProject\\Rocket Project\\venv\\Scripts\\mlagents-learn --run-id=landing --force --torch-device=cuda",
        "mlagents_version": "1.0.0",
        "mlagents_envs_version": "1.0.0",
        "communication_protocol_version": "1.5.0",
        "pytorch_version": "2.3.1+cu121",
        "numpy_version": "1.23.5",
        "end_time_seconds": "1724979532"
    },
    "total": 409.5432903000001,
    "count": 1,
    "self": 0.004388199999993958,
    "children": {
        "run_training.setup": {
            "total": 0.021725300000071,
            "count": 1,
            "self": 0.021725300000071
        },
        "TrainerController.start_learning": {
            "total": 409.5171768,
            "count": 1,
            "self": 0.356535899993105,
            "children": {
                "TrainerController._reset_env": {
                    "total": 11.85765900000024,
                    "count": 1,
                    "self": 11.85765900000024
                },
                "TrainerController.advance": {
                    "total": 397.20285730000705,
                    "count": 34583,
                    "self": 0.3598084000441304,
                    "children": {
                        "env_step": {
                            "total": 309.42559999992045,
                            "count": 34583,
                            "self": 125.34698069983278,
                            "children": {
                                "SubprocessEnvManager._take_step": {
                                    "total": 183.84220010013541,
                                    "count": 34583,
                                    "self": 1.1148269001623703,
                                    "children": {
                                        "TorchPolicy.evaluate": {
                                            "total": 182.72737319997304,
                                            "count": 31291,
                                            "self": 182.72737319997304
                                        }
                                    }
                                },
                                "workers": {
                                    "total": 0.2364191999522518,
                                    "count": 34583,
                                    "self": 0.0,
                                    "children": {
                                        "worker_root": {
                                            "total": 397.6694348999945,
                                            "count": 34583,
                                            "is_parallel": true,
                                            "self": 298.3921338999771,
                                            "children": {
                                                "steps_from_proto": {
                                                    "total": 0.00040700000045035267,
                                                    "count": 1,
                                                    "is_parallel": true,
                                                    "self": 0.00020010000116599258,
                                                    "children": {
                                                        "_process_rank_one_or_two_observation": {
                                                            "total": 0.0002068999992843601,
                                                            "count": 2,
                                                            "is_parallel": true,
                                                            "self": 0.0002068999992843601
                                                        }
                                                    }
                                                },
                                                "UnityEnvironment.step": {
                                                    "total": 99.27689400001691,
                                                    "count": 34583,
                                                    "is_parallel": true,
                                                    "self": 3.0568632999475085,
                                                    "children": {
                                                        "UnityEnvironment._generate_step_input": {
                                                            "total": 5.922437200039894,
                                                            "count": 34583,
                                                            "is_parallel": true,
                                                            "self": 5.922437200039894
                                                        },
                                                        "communicator.exchange": {
                                                            "total": 82.82728989995667,
                                                            "count": 34583,
                                                            "is_parallel": true,
                                                            "self": 82.82728989995667
                                                        },
                                                        "steps_from_proto": {
                                                            "total": 7.470303600072839,
                                                            "count": 34583,
                                                            "is_parallel": true,
                                                            "self": 3.7782438001631817,
                                                            "children": {
                                                                "_process_rank_one_or_two_observation": {
                                                                    "total": 3.692059799909657,
                                                                    "count": 69166,
                                                                    "is_parallel": true,
                                                                    "self": 3.692059799909657
                                                                }
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        },
                        "trainer_advance": {
                            "total": 87.41744890004247,
                            "count": 34583,
                            "self": 0.7682379001944355,
                            "children": {
                                "process_trajectory": {
                                    "total": 25.449906299852955,
                                    "count": 34583,
                                    "self": 25.316881599852422,
                                    "children": {
                                        "RLTrainer._checkpoint": {
                                            "total": 0.1330247000005329,
                                            "count": 1,
                                            "self": 0.1330247000005329
                                        }
                                    }
                                },
                                "_update_policy": {
                                    "total": 61.19930469999508,
                                    "count": 48,
                                    "self": 35.584405100002186,
                                    "children": {
                                        "TorchPPOOptimizer.update": {
                                            "total": 25.614899599992896,
                                            "count": 1440,
                                            "self": 25.614899599992896
                                        }
                                    }
                                }
                            }
                        }
                    }
                },
                "trainer_threads": {
                    "total": 5.000001692678779e-07,
                    "count": 1,
                    "self": 5.000001692678779e-07
                },
                "TrainerController._save_models": {
                    "total": 0.10012409999944794,
                    "count": 1,
                    "self": 0.0007368999995378545,
                    "children": {
                        "RLTrainer._checkpoint": {
                            "total": 0.09938719999991008,
                            "count": 1,
                            "self": 0.09938719999991008
                        }
                    }
                }
            }
        }
    }
}